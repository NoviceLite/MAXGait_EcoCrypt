{"cells":[{"cell_type":"code","execution_count":1,"id":"a2f915ca-7ab2-4230-99b0-95f695d8dcab","metadata":{"id":"a2f915ca-7ab2-4230-99b0-95f695d8dcab","executionInfo":{"status":"ok","timestamp":1744337890588,"user_tz":-480,"elapsed":10818,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["# Different layers\n","import tensorflow as tf\n","from tensorflow.keras.layers import MultiHeadAttention, Input, Dense\n","from tensorflow.keras.layers import LayerNormalization, BatchNormalization, Layer, Dropout\n","from tensorflow.keras.layers import GlobalAveragePooling1D, Conv1D\n","# For miscellaneous functions\n","from tensorflow import convert_to_tensor\n","from tensorflow.keras import utils\n","# Keras models\n","from tensorflow.keras import Model, Sequential\n","# For evaluation\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","# For math/arrays\n","import numpy as np\n","# For plotting\n","import matplotlib.pyplot as plt\n","# For importing and processing HybrIK files\n","import os\n","import pickle\n","import scipy.optimize\n","# For train test split\n","# from sklearn.model_selection import train_test_split\n","# For imbalanced dataset\n","#! pip install imbalanced-learn\n","#from imblearn.over_sampling import SMOTE\n","from tensorflow.keras.optimizers import Adam, RMSprop, Adagrad\n","import time"]},{"cell_type":"markdown","id":"l2KJuMYrMawf","metadata":{"id":"l2KJuMYrMawf"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":2,"id":"7177193c-0828-4c6b-b05a-377d0b8a7741","metadata":{"id":"7177193c-0828-4c6b-b05a-377d0b8a7741","executionInfo":{"status":"ok","timestamp":1744337890631,"user_tz":-480,"elapsed":36,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["def extract_gait_cycle(feet_distances):\n","    '''\n","    To extract gait cycle according to the pattern of graph\n","    Output: a list of estimated start and end index for gait cycles\n","    '''\n","    y = feet_distances\n","    close_feet_count = 0\n","    cycle_start = 0\n","\n","    if y[1] < y[0] :\n","        open_feet = False\n","        cycle_start = -1\n","    else:\n","        open_feet = True\n","\n","    cycle_list = list()\n","\n","    for i in range(1, len(feet_distances)):\n","        if y[i] < y[i-1] and open_feet:\n","            open_feet = False\n","        elif y[i] > y[i-1] and not open_feet:\n","            open_feet = True\n","            if cycle_start == -1:\n","                cycle_start = i\n","                continue\n","\n","            close_feet_count = close_feet_count + 1\n","            if close_feet_count % 2 == 0:\n","                cycle_end = i - 1\n","                cycle_list.append((cycle_start, cycle_end))\n","\n","                cycle_start = cycle_end\n","\n","    return cycle_list"]},{"cell_type":"code","execution_count":3,"id":"09ec2705-63d8-42c9-bc05-2a7d95804243","metadata":{"id":"09ec2705-63d8-42c9-bc05-2a7d95804243","executionInfo":{"status":"ok","timestamp":1744337890664,"user_tz":-480,"elapsed":32,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["def fit_sin(tt, yy):\n","    '''\n","    Use coordinates given to produce sine graph\n","    '''\n","    tt = np.array(tt)\n","    yy = np.array(yy)\n","\n","    ff = np.fft.fftfreq(len(tt), (tt[1]-tt[0]))\n","    Fyy = abs(np.fft.fft(yy))\n","    guess_freq = abs(ff[np.argmax(Fyy[1:])+1])\n","    guess_amp = np.std(yy) * 2.**0.5\n","    guess_offset = np.mean(yy)\n","    guess = np.array([guess_amp, 2.*np.pi*guess_freq, 0., guess_offset])\n","\n","    def sinfunc(t, A, w, p, c):  return A * np.sin(w*t + p) + c\n","    popt, pcov = scipy.optimize.curve_fit(sinfunc, tt, yy, p0=guess)\n","    A, w, p, c = popt\n","    f = w/(2.*np.pi)\n","    fitfunc = lambda t: A * np.sin(w*t + p) + c\n","    return {\"amp\": A, \"omega\": w, \"phase\": p, \"offset\": c, \"freq\": f, \"period\": 1./f, \"fitfunc\": fitfunc, \"maxcov\": np.max(pcov), \"rawres\": (guess,popt,pcov)}"]},{"cell_type":"code","execution_count":4,"id":"c6b12edb-ff1f-4608-8148-c5b9596b9d8a","metadata":{"id":"c6b12edb-ff1f-4608-8148-c5b9596b9d8a","executionInfo":{"status":"ok","timestamp":1744337890682,"user_tz":-480,"elapsed":10,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["def process_single_file (data, coord_pos) :\n","    '''\n","    data: all data from one single pickle file\n","    coord_pos: 0 for x coordinates, 1 for y coordinates, 2 for z coordinates\n","    '''\n","    LEFT_ANKLE = 7\n","    RIGHT_ANKLE = 8\n","    feet_distances = []\n","    gait_cycles = []\n","\n","\n","    # Get distance between left and right ankles as feet distance\n","    for i, frame in enumerate(data['pred_uvd']):\n","        LAnkle = frame[LEFT_ANKLE, coord_pos]\n","        RAnkle = frame[RIGHT_ANKLE, coord_pos]\n","\n","        feet_distance = abs(LAnkle - RAnkle)\n","        feet_distances.append(feet_distance)\n","\n","    # Fit the feet distances data into sine graph,\n","    # to remove outliers or inconsistent patterns\n","    x = np.array(range(0, len(feet_distances)))\n","    try:\n","        f = fit_sin(x, feet_distances)[\"fitfunc\"]\n","        y = f(x)\n","        gait_cycles = extract_gait_cycle(y)\n","        #print(gait_cycles)\n","    except:\n","        # Fit the feet distances data into polynomial graph,\n","        # when it cannot fit into sine graph or no gait cycles found from sine graph\n","        if len(gait_cycles) <= 0:\n","            from scipy.interpolate import splrep, splev\n","            max_distance = max(feet_distances)\n","            smoothness = max_distance ** 2\n","            bspl = splrep(x,feet_distances,s=smoothness)\n","            y = splev(x,bspl)\n","            gait_cycles = extract_gait_cycle(y)\n","            #print(gait_cycles)\n","\n","    return gait_cycles"]},{"cell_type":"code","execution_count":5,"id":"0efb40fd-59c8-41b7-a49f-cc73a0f284b4","metadata":{"id":"0efb40fd-59c8-41b7-a49f-cc73a0f284b4","executionInfo":{"status":"ok","timestamp":1744337890754,"user_tz":-480,"elapsed":65,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["def extract_gait_information(file, data):\n","    '''\n","    Get gait start and end index lists according to the gait's view\n","    '''\n","    if 'front' in file.lower() or 'back' in file.lower():\n","        return process_single_file(data, 2)\n","    elif 'left' in file.lower() or 'right' in file.lower():\n","        return process_single_file(data, 0)"]},{"cell_type":"code","execution_count":6,"id":"fc80b5cb-cbe8-4660-90fe-8637cd155f6f","metadata":{"id":"fc80b5cb-cbe8-4660-90fe-8637cd155f6f","executionInfo":{"status":"ok","timestamp":1744337890774,"user_tz":-480,"elapsed":9,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["def extract_data(input_file, max_length):\n","    '''\n","    Extract all samples and labels from the input file.\n","    Return any file not met maximum sequence length as error files\n","    '''\n","    all_samples = []\n","    all_labels = []\n","    error_files = []\n","\n","    for file in os.listdir(input_file):\n","\n","        # Process only HybrIK pickle files\n","        if not file.endswith('.pk'):\n","            continue\n","\n","        # Extract features with shape (sample_size, frame_num, keypoints_num * xyz)\n","        file_path = os.path.join(input_file, file)\n","        with open(file_path, 'rb') as f:\n","            data = pickle.load(f)\n","\n","        full_keypoints = data['pred_xyz_24_struct']\n","        #full_keypoints = data['pred_xyz_29']\n","        total_frames = len(full_keypoints)\n","\n","        gait_cycles = extract_gait_information(file, data)\n","        mid_index = len(gait_cycles) // 2\n","\n","        # Take middle gait cycles if possible\n","        start_index = gait_cycles[mid_index][0] if len(gait_cycles) > 0 else 0\n","        final_index = start_index + max_length - 1\n","\n","        # If max sequence length is greater than total frames of files,\n","        # the file will not be used for processing\n","        if final_index >= total_frames:\n","            if max_length <= total_frames:\n","                start_index = 0\n","                final_index = max_length - 1\n","            else:\n","                error_files.append((file, total_frames))\n","                continue\n","\n","        keypoints = []\n","\n","        for i in range(start_index, final_index + 1) :\n","            keypoints.append(list(full_keypoints[i].flat))\n","\n","        # Extract label\n","        # Check for gender\n","        if 'F' in file:\n","            gender = 1\n","        else:\n","            gender = 0\n","\n","        # Check for age group\n","        from drive.MyDrive.model_preprocessing import process\n","        #from model_preprocessing import process\n","        age = process(file)\n","        #age = int(file.split(\"_\")[3])\n","        if age <= 0:\n","            continue\n","        elif age < 15:\n","            group = 0 # Child group\n","        elif age < 65:\n","            group = 1 # Adult group\n","        else:\n","            group = 2 # Senior group\n","\n","        # Male child = 0\n","        # Female child = 1\n","        # Male adult = 2\n","        # Female adult = 3\n","        # Male senior = 4\n","        # Female senior = 5\n","        label = 2 * group + gender\n","\n","        all_samples.append(keypoints)\n","        all_labels.append(label)\n","\n","    return all_samples, all_labels, error_files"]},{"cell_type":"code","execution_count":7,"id":"0834ee5d-146b-4a70-92de-10807ab6241b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":80943,"status":"ok","timestamp":1744337971719,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"},"user_tz":-480},"id":"0834ee5d-146b-4a70-92de-10807ab6241b","outputId":"c1a127a2-b017-4f99-8317-d9849e101f89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Train set: 877 \n","Test set: 274 \n","Validation set: 219\n"]}],"source":["# Locate dataset for train, validation and test set\n","# Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","input_folder = \"/content/drive/MyDrive\"\n","test_folder = os.path.join(input_folder, \"PK_test_set\")\n","train_folder = os.path.join(input_folder, \"PK_train_set\")\n","validation_folder = os.path.join(input_folder, \"PK_validation_set\")\n","\n","# Locate dataset for train, validation and test set\n","#input_folder = r\"C:\\Users\\Asus\\Downloads\"\n","#test_folder = os.path.join(input_folder, \"PK_test_set\")\n","#train_folder = os.path.join(input_folder, \"PK_train_set\")\n","#validation_folder = os.path.join(input_folder, \"PK_validation_set\")\n","\n","# Set sequence length\n","sequence_length = 60\n","\n","# Retrieve dataset\n","all_error_files = []\n","X_train, y_train, error_files = extract_data(train_folder, sequence_length)\n","all_error_files.extend(error_files)\n","X_test, y_test, error_files = extract_data(test_folder, sequence_length)\n","all_error_files.extend(error_files)\n","X_val, y_val, error_files = extract_data(validation_folder, sequence_length)\n","all_error_files.extend(error_files)\n","\n","# Print processing results\n","print(\"Train set:\", len(X_train), \"\\nTest set:\", len(X_test), \"\\nValidation set:\", len(X_val))\n","if len(all_error_files) > 0:\n","    print(\"Error in processing files:\")\n","    for file in all_error_files:\n","        print(f\"\\t- {file[0]} ({file[1]} frames)\")"]},{"cell_type":"code","execution_count":8,"id":"07a6fa4c-fc8a-42bc-9e77-0f05d2403edb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2944,"status":"ok","timestamp":1744337974662,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"},"user_tz":-480},"id":"07a6fa4c-fc8a-42bc-9e77-0f05d2403edb","outputId":"355e6f2f-ff0c-451a-cc3d-488ae3cf2840"},"outputs":[{"output_type":"stream","name":"stdout","text":["877 274 877 274\n","(877, 60, 72)\n","6\n"]}],"source":["# Calculate number of output classes\n","n_classes = len(np.unique(y_train))\n","\n","# Calculate dimension of vector that similar to embedding\n","num_coord = 24\n","xyz = 3\n","embed_dim = num_coord * xyz\n","\n","# For balancing classes\n","#X_train_array = np.array(X_train)\n","#X_train_2d = X_train_array.reshape((X_train_array.shape[0], sequence_length * embed_dim))\n","#smote = SMOTE(random_state = 42)\n","#X_train_resampled, y_train_resampled = smote.fit_resample(X_train_2d, y_train)\n","#X_train_3d = X_train_resampled.reshape((X_train_resampled.shape[0], sequence_length, embed_dim))\n","\n","# Convert list to tensor\n","#X_train_tensor = convert_to_tensor(X_train_3d, dtype = np.float32)\n","X_train_tensor = convert_to_tensor(X_train, dtype = np.float32)\n","X_test_tensor = convert_to_tensor(X_test, dtype = np.float32)\n","X_val_tensor = convert_to_tensor(X_val, dtype = np.float32)\n","\n","# Convert labels using one hot encoding\n","#y_train_categorical = utils.to_categorical(y_train_resampled)\n","y_train_categorical = utils.to_categorical(y_train)\n","y_test_categorical = utils.to_categorical(y_test)\n","y_val_categorical = utils.to_categorical(y_val)\n","\n","# Print processing results\n","#print(len(X_train_tensor), len(X_test_tensor), len(y_train_resampled), len(y_test))\n","print(len(X_train_tensor), len(X_test_tensor), len(y_train), len(y_test))\n","print(X_train_tensor.shape)\n","print(n_classes)"]},{"cell_type":"code","execution_count":9,"id":"12fe885f-2102-4ec8-abc3-626e7cd9aa62","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1744337974670,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"},"user_tz":-480},"id":"12fe885f-2102-4ec8-abc3-626e7cd9aa62","outputId":"a4dc2c32-3755-4487-adda-8b1d0e1fda0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["{np.int64(0): np.int64(118), np.int64(1): np.int64(75), np.int64(2): np.int64(249), np.int64(3): np.int64(305), np.int64(4): np.int64(72), np.int64(5): np.int64(58)}\n"]}],"source":["# Check frequency of each class in train dataset\n","label, counts = np.unique(y_train, return_counts=True)\n","#label, counts = np.unique(y_train_resampled, return_counts=True)\n","print(dict(zip(label, counts)))"]},{"cell_type":"markdown","id":"4fB-TrSvMixi","metadata":{"id":"4fB-TrSvMixi"},"source":["## Model Compilation"]},{"cell_type":"markdown","id":"MgUOiLjuNaiD","metadata":{"id":"MgUOiLjuNaiD"},"source":["### Transformer Block"]},{"cell_type":"code","execution_count":10,"id":"652bcf53-5741-4209-9775-aea5838ab249","metadata":{"id":"652bcf53-5741-4209-9775-aea5838ab249","executionInfo":{"status":"ok","timestamp":1744337974698,"user_tz":-480,"elapsed":20,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["class Config:\n","    def __init__(self):\n","        #self.vocab_size = 32000\n","        self.d_model = 72\n","        #self.n_layers = 2\n","        self.n_heads = 2\n","        self.d_kv_comp = 16\n","        self.d_rope = 16\n","        #self.n_experts = 32\n","        #self.n_shared = 2\n","        #self.top_k = 2\n","        self.seq_len = 60\n","        #self.batch_size = 8\n","        #self.ffn_dim = 384\n","        #self.device_groups = 4 # For device-limited routing\n","\n","config = Config()\n","\n","class RotaryEmbedding(tf.keras.Model):\n","    def __init__(self, dim, scale=40):\n","        super().__init__()\n","        assert dim % 2 == 0, \"Dimension must be even for rotary embeddings\"\n","        self.dim = dim\n","        self.inv_freq = 1.0 / (10000 ** (tf.range(0, dim // 2, 2, dtype=tf.float32) / (dim // 2)))\n","        self.scale = scale\n","\n","    def call(self, seq_len):\n","        t = tf.range(seq_len, dtype=self.inv_freq.dtype) / self.scale\n","        freqs = tf.einsum(\"i,j->ij\", t, self.inv_freq)\n","        return tf.concat([freqs, freqs], axis=-1)\n","\n","def rotate_half(x):\n","    x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n","    return tf.concat([-x2, x1], axis=-1)\n","\n","def apply_rotary(x, cos, sin):\n","    \"\"\"\n","    Apply rotary embeddings to the first half of x.\n","    \"\"\"\n","    # Split x into two parts: one for rotary embeddings and the other untouched\n","    x_rot, x_base = tf.split(x, num_or_size_splits=[tf.shape(cos)[-1], tf.shape(x)[-1] - tf.shape(cos)[-1]], axis=-1)\n","    # Apply rotary embeddings to the rotary part\n","    x_rot = (x_rot * cos) + (rotate_half(x_rot) * sin)\n","    # Concatenate the rotary-applied and base parts\n","    return tf.concat([x_rot, x_base], axis=-1)\n","\n","class MemoryOptimizedMLA(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.d_head = config.d_model // config.n_heads\n","        self.split_dim = self.d_head - config.d_rope\n","\n","        # Projections\n","        self.W_dkv = tf.keras.layers.Dense(config.d_kv_comp, input_shape=(config.d_model,))\n","        self.W_dq = tf.keras.layers.Dense(config.d_kv_comp, input_shape=(config.d_model,))\n","\n","        # Changed value projection to use d_head instead of split_dim\n","        self.W_uk = tf.keras.layers.Dense(config.n_heads * self.split_dim, input_shape=(config.d_kv_comp,))\n","        self.W_uv = tf.keras.layers.Dense(config.n_heads * self.d_head, input_shape=(config.d_kv_comp,))\n","        self.W_uq = tf.keras.layers.Dense(config.n_heads * self.split_dim, input_shape=(config.d_kv_comp,))\n","\n","        self.W_qr = tf.keras.layers.Dense(config.n_heads * config.d_rope, input_shape=(config.d_kv_comp,))\n","        self.W_kr = tf.keras.layers.Dense(config.n_heads * config.d_rope, input_shape=(config.d_model,))\n","\n","        self.rotary = RotaryEmbedding(config.d_rope)\n","        self.output_proj = tf.keras.layers.Dense(config.d_model, input_shape=(config.n_heads * self.d_head,))\n","\n","    def call(self, h, past_kv=None):\n","        batch_size, seq_len, _ = tf.shape(h)[0], tf.shape(h)[1], tf.shape(h)[-1]\n","\n","        # KV Compression\n","        c_kv = self.W_dkv(h)\n","        k = tf.reshape(self.W_uk(c_kv), (batch_size, seq_len, config.n_heads, self.split_dim))\n","        v = tf.reshape(self.W_uv(c_kv), (batch_size, seq_len, config.n_heads, self.d_head))\n","\n","        # Query Compression\n","        c_q = self.W_dq(h)\n","        q_base = tf.reshape(self.W_uq(c_q), (batch_size, seq_len, config.n_heads, self.split_dim))\n","        q_rot = tf.reshape(self.W_qr(c_q), (batch_size, seq_len, config.n_heads, config.d_rope))\n","\n","        # Rotary embeddings with proper dimensions\n","        rotary_emb = self.rotary(seq_len)\n","        cos = tf.reshape(tf.cos(rotary_emb), (1, seq_len, 1, -1))  # [1, seq, 1, dim]\n","        sin = tf.reshape(tf.sin(rotary_emb), (1, seq_len, 1, -1))\n","\n","        # Apply rotary embeddings\n","        q_rot = apply_rotary(q_rot, cos, sin)\n","        k_rot = apply_rotary(\n","            tf.reshape(self.W_kr(h), (batch_size, seq_len, config.n_heads, config.d_rope)),\n","            cos, sin\n","        )\n","\n","        q = tf.concat([q_base, q_rot], axis=-1)\n","        k = tf.concat([k, k_rot], axis=-1)\n","\n","        #q = q_base\n","        #k = k\n","\n","        # Attention computation\n","        scores = tf.einsum(\"bqhd,bkhd->bhqk\", q, k) / tf.sqrt(tf.cast(self.d_head, dtype=tf.float32))\n","        attn = tf.nn.softmax(scores, axis=-1)\n","        out = tf.einsum(\"bhqk,bkhd->bqhd\", attn, v)\n","\n","        #return self.output_proj(tf.reshape(out, (batch_size, seq_len, -1))), (c_kv, k_rot)\n","        return self.output_proj(tf.reshape(out, (batch_size, seq_len, config.d_model)))"]},{"cell_type":"code","execution_count":11,"id":"a530bade-299f-41f2-9843-0cf610864563","metadata":{"id":"a530bade-299f-41f2-9843-0cf610864563","executionInfo":{"status":"ok","timestamp":1744337974704,"user_tz":-480,"elapsed":4,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["class EncoderLayer(Layer):\n","    def __init__(self, total_heads, total_dense_units, embed_dim):\n","        super(EncoderLayer, self).__init__()\n","        self.multihead = MultiHeadAttention(num_heads=total_heads, key_dim=embed_dim) # Multihead attention layer\n","        self.nnw = Sequential([Dense(total_dense_units, activation=\"relu\"), Dense(embed_dim)]) # Feed forward network layer\n","        self.normalize_layer = LayerNormalization() # Normalization\n","\n","    def call(self, inputs):\n","        attn_output = self.multihead(inputs, inputs)\n","        normalize_attn = self.normalize_layer(inputs + attn_output)\n","        nnw_output = self.nnw(normalize_attn)\n","        final_output = self.normalize_layer(normalize_attn + nnw_output)\n","        return final_output"]},{"cell_type":"markdown","id":"QYLcw414NfUn","metadata":{"id":"QYLcw414NfUn"},"source":["### Mamba block"]},{"cell_type":"code","execution_count":12,"id":"5cb57465-94df-420f-aa1c-587489709d3c","metadata":{"id":"5cb57465-94df-420f-aa1c-587489709d3c","executionInfo":{"status":"ok","timestamp":1744337974750,"user_tz":-480,"elapsed":38,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["from tensorflow.keras import initializers, regularizers, constraints\n","\n","class RMSNorm(Layer):\n","    def __init__(self, epsilon=1e-7, gamma_initializer='ones', gamma_regularizer=None, gamma_constraint=None, **kwargs):\n","        super(RMSNorm, self).__init__(**kwargs)\n","        self.epsilon = epsilon\n","        self.gamma_initializer = initializers.get(gamma_initializer)\n","        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n","        self.gamma_constraint = constraints.get(gamma_constraint)\n","\n","    def build(self, input_shape):\n","        shape = (input_shape[-1],)\n","        self.gamma = self.add_weight(name='gamma',\n","                                     shape=shape,\n","                                     initializer=self.gamma_initializer,\n","                                     regularizer=self.gamma_regularizer,\n","                                     constraint=self.gamma_constraint,\n","                                     trainable=True)\n","        super(RMSNorm, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        rms = tf.sqrt(tf.reduce_mean(tf.square(inputs), axis=-1, keepdims=True) + self.epsilon)\n","        return self.gamma * inputs / rms\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape"]},{"cell_type":"code","execution_count":13,"id":"3b6891b0-bd6b-4d43-b65d-aa72d16b6918","metadata":{"id":"3b6891b0-bd6b-4d43-b65d-aa72d16b6918","executionInfo":{"status":"ok","timestamp":1744337974763,"user_tz":-480,"elapsed":15,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["from dataclasses import dataclass\n","from typing import Union\n","from tensorflow import keras\n","import math\n","from tensorflow.keras import layers\n","from einops import rearrange, repeat\n","\n","# Argument for MAMBA block configuration\n","@dataclass\n","class ModelArgs:\n","    model_input_dims: int = 64\n","    model_states: int = 64\n","    projection_expand_factor: int = 2\n","    conv_kernel_size: int = 4\n","    delta_t_min: float = 0.001\n","    delta_t_max: float = 0.1\n","    delta_t_scale: float = 0.1\n","    delta_t_init_floor: float = 1e-4\n","    conv_use_bias: bool = True\n","    dense_use_bias: bool = False\n","    layer_id: int = -1\n","    seq_length: int = 128\n","    use_lm_head: float = False\n","\n","    def __post_init__(self):\n","        self.model_internal_dim: int = int(self.projection_expand_factor * self.model_input_dims)\n","\n","        self.delta_t_rank = math.ceil(self.model_input_dims/16)\n","        if self.layer_id == -1:\n","            self.layer_id = np.round(np.random.randint(0, 1000), 4)"]},{"cell_type":"code","execution_count":14,"id":"81a008a3-2f91-438b-81bb-acbacaf78f6c","metadata":{"id":"81a008a3-2f91-438b-81bb-acbacaf78f6c","executionInfo":{"status":"ok","timestamp":1744337974765,"user_tz":-480,"elapsed":16,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["def selective_scan(u, delta, A, B, C, D):\n","    # first step of A_bar = exp(ΔA), i.e., ΔA\n","    dA = tf.einsum('bld,dn->bldn', delta, A)\n","    dB_u = tf.einsum('bld,bld,bln->bldn', delta, u, B)\n","\n","    dA_cumsum = tf.pad(\n","        dA[:, 1:], [[0, 0], [1, 1], [0, 0], [0, 0]])[:, 1:, :, :]\n","\n","    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip along axis 1\n","\n","    # Cumulative sum along all the input tokens, parallel prefix sum,\n","    # calculates dA for all the input tokens parallely\n","    dA_cumsum = tf.math.cumsum(dA_cumsum, axis=1)\n","\n","    # second step of A_bar = exp(ΔA), i.e., exp(ΔA)\n","    dA_cumsum = tf.exp(dA_cumsum)\n","    dA_cumsum = tf.reverse(dA_cumsum, axis=[1])  # Flip back along axis 1\n","\n","    x = dB_u * dA_cumsum\n","    # 1e-12 to avoid division by 0\n","    x = tf.math.cumsum(x, axis=1)/(dA_cumsum + 1e-12)\n","\n","    y = tf.einsum('bldn,bln->bld', x, C)\n","\n","    return y + u * D"]},{"cell_type":"code","execution_count":15,"id":"4c2ba0a6-675b-4e72-b2a5-8d7510e0ba90","metadata":{"id":"4c2ba0a6-675b-4e72-b2a5-8d7510e0ba90","executionInfo":{"status":"ok","timestamp":1744337974772,"user_tz":-480,"elapsed":9,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["class MambaBlock(layers.Layer):\n","    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.args = modelargs\n","        args = modelargs\n","        self.layer_id = modelargs.layer_id\n","\n","        self.in_projection = layers.Dense(\n","            args.model_internal_dim * 2,\n","            input_shape=(args.model_input_dims,), use_bias=False)\n","\n","        self.conv1d = layers.Conv1D(\n","            filters=args.model_internal_dim,\n","            use_bias=args.conv_use_bias,\n","            kernel_size=args.conv_kernel_size,\n","            groups=args.model_internal_dim,\n","            data_format='channels_first',\n","            padding='causal'\n","        )\n","\n","        # this layer takes in current token 'x'\n","        # and outputs the input-specific Δ, B, C (according to S6)\n","        self.x_projection = layers.Dense(args.delta_t_rank + args.model_states * 2, use_bias=False)\n","\n","        # this layer projects Δ from delta_t_rank to the mamba internal\n","        # dimension\n","        self.delta_t_projection = layers.Dense(args.model_internal_dim,\n","                                               input_shape=(args.delta_t_rank,), use_bias=True)\n","\n","        self.A = repeat(\n","                tf.range(1, args.model_states+1, dtype=tf.float32),\n","                'n -> d n', d=args.model_internal_dim)\n","\n","        self.A_log = tf.Variable(\n","                tf.math.log(self.A),\n","                trainable=True, dtype=tf.float32,\n","                name=f\"SSM_A_log_{args.layer_id}\")\n","\n","        self.D = tf.Variable(\n","                np.ones(args.model_internal_dim),\n","                trainable=True, dtype=tf.float32,\n","                name=f\"SSM_D_{args.layer_id}\")\n","\n","        self.out_projection = layers.Dense(\n","                args.model_input_dims,\n","                input_shape=(args.model_internal_dim,),\n","                use_bias=args.dense_use_bias)\n","\n","    def call(self, x):\n","        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba pape.\n","        Official Implementation:\n","            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n","            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n","        \"\"\"\n","\n","        (batch_size, seq_len, dimension) = x.shape\n","\n","        x_and_res = self.in_projection(x) # shape = (batch, seq_len, 2 * model_internal_dimension)\n","        (x, res) = tf.split(x_and_res,\n","                            [self.args.model_internal_dim,\n","                             self.args.model_internal_dim], axis=-1)\n","\n","        x = rearrange(x, 'b l d_in -> b d_in l')\n","        x = self.conv1d(x)[:, :, :seq_len]\n","        x = rearrange(x, 'b d_in l -> b l d_in')\n","\n","        x = tf.nn.swish(x)\n","        y = self.ssm(x)\n","        y = y * tf.nn.swish(res)\n","        return self.out_projection(y)\n","\n","    def ssm(self, x):\n","        \"\"\"Runs the SSM. See:\n","            - Algorithm 2 in Section 3.2 in the Mamba paper\n","            - run_SSM(A, B, C, u) in The Annotated S4\n","            Official Implementation:\n","            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n","        \"\"\"\n","        (d_in, n) = self.A_log.shape\n","\n","        # Compute ∆ A B C D, the state space parameters.\n","        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n","        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n","        #                                  and is why Mamba is called **selective** state spaces)\n","\n","        A = -tf.exp(tf.cast(self.A_log, tf.float32)) # shape -> (d_in, n)\n","        D = tf.cast(self.D, tf.float32)\n","\n","        x_dbl = self.x_projection(x) # shape -> (batch, seq_len, delta_t_rank + 2*n)\n","\n","        (delta, B, C) = tf.split(\n","                x_dbl,\n","                num_or_size_splits=[self.args.delta_t_rank, n, n],\n","                axis=-1) # delta.shape -> (batch, seq_len) & B, C shape -> (batch, seq_len, n)\n","\n","        delta = tf.nn.softplus(self.delta_t_projection(delta)) # shape -> (batch, seq_len, model_input_dim)\n","\n","        return selective_scan(x, delta, A, B, C, D)"]},{"cell_type":"code","execution_count":16,"id":"e25350ce-e3b6-4dd4-9a4e-329c02456a72","metadata":{"id":"e25350ce-e3b6-4dd4-9a4e-329c02456a72","executionInfo":{"status":"ok","timestamp":1744337974840,"user_tz":-480,"elapsed":61,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}}},"outputs":[],"source":["class ResidualBlock(layers.Layer):\n","    def __init__(self, modelargs: ModelArgs, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.args = modelargs\n","        self.mixer = MambaBlock(modelargs)\n","        self.norm = LayerNormalization(epsilon=1e-5)\n","        #self.norm = BatchNormalization(epsilon=1e-5)\n","        #self.norm = RMSNorm(epsilon=1e-5)\n","\n","    def call(self, x):\n","        \"\"\"\n","        Official Implementation:\n","            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n","\n","            Note: the official repo chains residual blocks that look like\n","                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n","            where the first Add is a no-op. This is purely for performance reasons as this\n","            allows them to fuse the Add->Norm.\n","\n","            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n","                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n","\n","        \"\"\"\n","        return self.mixer(self.norm(x)) + x"]},{"cell_type":"markdown","id":"JsqlmUrkx4up","metadata":{"id":"JsqlmUrkx4up"},"source":["# Model Comparison"]},{"cell_type":"code","execution_count":null,"id":"48d2232a-f52c-4579-959f-dd9410d87dfb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":547699,"status":"ok","timestamp":1742630338489,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"},"user_tz":-480},"id":"48d2232a-f52c-4579-959f-dd9410d87dfb","outputId":"5374a958-0140-4574-9491-401c6caaf825"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- Training 1 ------------------\n","Time elapsed: 104.98905849456787 s\n","Loss: 1.1002564430236816\n","Accuracy: 66.42%\n","Precision: 65.43%\n","Recall: 58.03%\n","-------------- Training 2 ------------------\n","Time elapsed: 105.98374581336975 s\n","Loss: 1.2942030429840088\n","Accuracy: 64.60%\n","Precision: 66.13%\n","Recall: 59.85%\n","-------------- Training 3 ------------------\n","Time elapsed: 109.6634464263916 s\n","Loss: 1.243756651878357\n","Accuracy: 61.31%\n","Precision: 64.82%\n","Recall: 59.85%\n","-------------- Training 4 ------------------\n","Time elapsed: 104.76738357543945 s\n","Loss: 1.2949206829071045\n","Accuracy: 63.14%\n","Precision: 68.16%\n","Recall: 60.95%\n","-------------- Training 5 ------------------\n","Time elapsed: 109.74663162231445 s\n","Loss: 1.2994319200515747\n","Accuracy: 59.49%\n","Precision: 63.67%\n","Recall: 56.93%\n","--------------------------------------------------------------\n","Average execution time (s): 107.03017845153809\n","SD of execution time: 2.222364327895821\n","Average accuracy: 62.99270153045654\n","SD accuracy: 2.427486923733448\n","Average precision: 65.6440007686615\n","SD precision: 1.4956811477931926\n","Average recall: 59.12408709526062\n","SD recall: 1.4414882889564937\n"]}],"source":["# Transformer block\n","num_heads = 2\n","total_dense_units = 256\n","\n","t = []\n","acc = []\n","pcs = []\n","rc = []\n","\n","for i in range(5):\n","    print(f\"-------------- Training {i + 1} ------------------\")\n","    # Setting seed for reproducibility\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    # Compile model\n","    input_layer = Input(shape=(sequence_length, embed_dim))\n","    attn_layer_0 = EncoderLayer(num_heads, total_dense_units, embed_dim)(input_layer)\n","    pool = GlobalAveragePooling1D()(attn_layer_0)\n","    d = Dense(total_dense_units, activation=\"relu\")(pool)\n","    output_layer = Dense(n_classes, activation=\"softmax\")(d)\n","\n","    # Construct the model\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    optimizer = Adam(learning_rate = 0.0001)\n","    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy', 'Precision', 'Recall'])\n","\n","    # Train the model and record execution time\n","    start = time.time()\n","    history = model.fit(\n","        X_train_tensor,\n","        y_train_categorical,\n","        batch_size=8,\n","        epochs=150,\n","        validation_data=(X_val_tensor, y_val_categorical),\n","        verbose = 0,\n","    )\n","\n","    print(\"Time elapsed:\", time.time() - start, \"s\")\n","    t.append(time.time() - start)\n","\n","    # Evaluate on test dataset\n","    scores = model.evaluate(X_test_tensor, y_test_categorical, verbose = 0)\n","    print(\"Loss:\", scores[0])\n","    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n","    print(\"Precision: %.2f%%\" % (scores[2] * 100))\n","    print(\"Recall: %.2f%%\" % (scores[3] * 100))\n","    acc.append(scores[1] * 100)\n","    pcs.append(scores[2] * 100)\n","    rc.append(scores[3] * 100)\n","\n","print(\"--------------------------------------------------------------\")\n","print(\"Average execution time (s):\", np.mean(t))\n","print(\"SD of execution time:\", np.std(t))\n","print(\"Average accuracy:\", np.mean(acc))\n","print(\"SD accuracy:\", np.std(acc))\n","print(\"Average precision:\", np.mean(pcs))\n","print(\"SD precision:\", np.std(pcs))\n","print(\"Average recall:\", np.mean(rc))\n","print(\"SD recall:\", np.std(rc))"]},{"cell_type":"code","execution_count":null,"id":"0e82e1a2-5e97-4fd9-8139-d9935e3a22f9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0e82e1a2-5e97-4fd9-8139-d9935e3a22f9","executionInfo":{"status":"ok","timestamp":1742632204435,"user_tz":-480,"elapsed":1865945,"user":{"displayName":"Play More Have Fun","userId":"01965875402630766810"}},"outputId":"00bfc6fd-37be-4698-86e4-174cc1355007"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- Training 1 ------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Time elapsed: 375.2159550189972 s\n","Loss: 6.5642218589782715\n","Accuracy: 57.66%\n","Precision: 57.66%\n","Recall: 57.66%\n","-------------- Training 2 ------------------\n","Time elapsed: 367.70885729789734 s\n","Loss: 5.851922988891602\n","Accuracy: 60.95%\n","Precision: 61.17%\n","Recall: 60.95%\n","-------------- Training 3 ------------------\n","Time elapsed: 363.10615706443787 s\n","Loss: 5.800812721252441\n","Accuracy: 63.50%\n","Precision: 63.74%\n","Recall: 63.50%\n","-------------- Training 4 ------------------\n","Time elapsed: 369.1279101371765 s\n","Loss: 10.087162971496582\n","Accuracy: 60.95%\n","Precision: 61.17%\n","Recall: 60.95%\n","-------------- Training 5 ------------------\n","Time elapsed: 361.2685458660126 s\n","Loss: 5.300381660461426\n","Accuracy: 60.95%\n","Precision: 61.17%\n","Recall: 60.95%\n","--------------------------------------------------------------\n","Average execution time (s): 367.28567185401914\n","SD of execution time: 4.901810912125173\n","Average accuracy: 60.80291748046875\n","SD accuracy: 1.8552202759091474\n","Average precision: 60.98339796066284\n","SD precision: 1.9340130415719254\n","Average recall: 60.80291748046875\n","SD recall: 1.8552202759091474\n"]}],"source":["# Mamba block\n","args = ModelArgs(\n","    model_input_dims=embed_dim,\n","    seq_length=sequence_length,\n","    #projection_expand_factor = 6,\n",")\n","\n","t = []\n","acc = []\n","pcs = []\n","rc = []\n","\n","for i in range(5):\n","    print(f\"-------------- Training {i + 1} ------------------\")\n","    # Setting seed for reproducibility\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    # Compile model\n","    input_layer = Input(shape=(sequence_length, embed_dim))\n","    mamba_layer_0 = ResidualBlock(args)(input_layer)\n","    mamba_layer_1 = ResidualBlock(args)(mamba_layer_0)\n","    mamba_layer_2 = ResidualBlock(args)(mamba_layer_1)\n","    pool = GlobalAveragePooling1D()(mamba_layer_2)\n","    d = Dense(total_dense_units, activation=\"relu\")(pool)\n","    output_layer = Dense(n_classes, activation=\"softmax\")(d)\n","\n","    # Construct the model\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    optimizer = Adam(learning_rate = 0.0001)\n","    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy', 'Precision', 'Recall'])\n","\n","    # Train the model and record execution time\n","    start = time.time()\n","    history = model.fit(\n","        X_train_tensor,\n","        y_train_categorical,\n","        batch_size=8,\n","        epochs=150,\n","        validation_data=(X_val_tensor, y_val_categorical),\n","        verbose = 0,\n","    )\n","\n","    print(\"Time elapsed:\", time.time() - start, \"s\")\n","    t.append(time.time() - start)\n","\n","    # Evaluate on test dataset\n","    scores = model.evaluate(X_test_tensor, y_test_categorical, verbose = 0)\n","    print(\"Loss:\", scores[0])\n","    print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n","    print(\"Precision: %.2f%%\" % (scores[2] * 100))\n","    print(\"Recall: %.2f%%\" % (scores[3] * 100))\n","    acc.append(scores[1] * 100)\n","    pcs.append(scores[2] * 100)\n","    rc.append(scores[3] * 100)\n","\n","print(\"--------------------------------------------------------------\")\n","print(\"Average execution time (s):\", np.mean(t))\n","print(\"SD of execution time:\", np.std(t))\n","print(\"Average accuracy:\", np.mean(acc))\n","print(\"SD accuracy:\", np.std(acc))\n","print(\"Average precision:\", np.mean(pcs))\n","print(\"SD precision:\", np.std(pcs))\n","print(\"Average recall:\", np.mean(rc))\n","print(\"SD recall:\", np.std(rc))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["l2KJuMYrMawf","4fB-TrSvMixi"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":5}